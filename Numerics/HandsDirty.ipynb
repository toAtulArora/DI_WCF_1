{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning by Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple SDP solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres   k/t\n",
      " 0:  1.5678e+00  1.5678e+00  9e+00  3e+00  4e-01  1e+00\n",
      " 1:  2.4030e+00  2.4911e+00  5e-01  3e-01  4e-02  2e-01\n",
      " 2:  2.6535e+00  2.6672e+00  7e-02  4e-02  5e-03  3e-02\n",
      " 3:  2.6456e+00  2.6514e+00  2e-02  1e-02  2e-03  1e-02\n",
      " 4:  2.6544e+00  2.6555e+00  5e-03  3e-03  4e-04  2e-03\n",
      " 5:  2.6540e+00  2.6542e+00  1e-03  7e-04  1e-04  5e-04\n",
      " 6:  2.6544e+00  2.6544e+00  3e-04  2e-04  2e-05  1e-04\n",
      " 7:  2.6543e+00  2.6543e+00  7e-05  4e-05  6e-06  3e-05\n",
      " 8:  2.6543e+00  2.6544e+00  2e-05  9e-06  1e-06  6e-06\n",
      " 9:  2.6543e+00  2.6543e+00  3e-06  2e-06  2e-07  1e-06\n",
      "10:  2.6543e+00  2.6543e+00  6e-07  3e-07  5e-08  2e-07\n",
      "11:  2.6543e+00  2.6543e+00  1e-07  5e-08  7e-09  3e-08\n",
      "Optimal solution found.\n",
      "The optimal value is 2.6543479996361037\n",
      "A solution X is\n",
      "[[ 1.60816352 -0.59785914 -0.69585439]\n",
      " [-0.59785914  0.22238688  0.24705027]\n",
      " [-0.69585439  0.24705027  1.3970322 ]]\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "# Generate a random SDP.\n",
    "n = 3\n",
    "p = 3\n",
    "np.random.seed(1)\n",
    "C = np.random.randn(n, n)\n",
    "A = []\n",
    "b = []\n",
    "for i in range(p):\n",
    "    A.append(np.random.randn(n, n))\n",
    "    b.append(np.random.randn())\n",
    "\n",
    "# Define and solve the CVXPY problem.\n",
    "# Create a symmetric matrix variable.\n",
    "X = cp.Variable((n,n), symmetric=True)\n",
    "# The operator >> denotes matrix inequality.\n",
    "\n",
    "constraints = [X >> 0]\n",
    "constraints += [\n",
    "    cp.trace(A[i] @ X) == b[i] for i in range(p)\n",
    "]\n",
    "\n",
    "prob = cp.Problem(cp.Minimize(cp.trace(C @ X)),\n",
    "                  constraints)\n",
    "prob.solve(solver=cp.CVXOPT,verbose=True)\n",
    "\n",
    "# Print result.\n",
    "print(\"The optimal value is\", prob.value)\n",
    "print(\"A solution X is\")\n",
    "print(X.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figuring how to use Tensor products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.physics.quantum.qubit import Qubit\n",
    "from sympy.physics.quantum.dagger import Dagger\n",
    "from sympy.physics.quantum import TensorProduct\n",
    "import sympy.physics.quantum as sq\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the functionality of sympy Quantum \n",
    "(imported from the swapKCBS project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Extending tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def powerDrop(expr):\n",
    "    if isinstance(expr,sp.Pow): #TODO: make sure the base is not too complex\n",
    "        # print(\"PowerEncountered\")\n",
    "        if expr.exp>=2:\n",
    "            # print(\"glaba\")\n",
    "            # display(expr.base)\n",
    "            _=sq.qapply(sp.Mul(expr.base,expr.base))\n",
    "            if expr.exp>2:\n",
    "                return powerDrop(_*sp.Pow(expr.base,expr.exp-2))\n",
    "            else:\n",
    "                return _\n",
    "        else:\n",
    "            return expr #autoDropDim(sp.Mul(expr.base,expr.base))\n",
    "    else:\n",
    "        if expr.has(sp.Pow):\n",
    "            #if it is a sum or a product, run this function for each part and then combine the parts; return the result\n",
    "            if isinstance(expr,sp.Mul) or isinstance(expr,sp.Add) or isinstance(expr,sq.TensorProduct):\n",
    "                new_args=[] #list(expr.args)\n",
    "                for _ in expr.args:\n",
    "                    new_args.append(powerDrop(_))\n",
    "                if isinstance(expr,sp.Mul):        \n",
    "                    return sp.Mul(*new_args)\n",
    "                elif isinstance(expr,sp.Add):\n",
    "                    return sp.Add(*new_args)  \n",
    "                elif isinstance(expr,sq.TensorProduct):\n",
    "                    return sq.TensorProduct(*new_args)  \n",
    "\n",
    "            else:\n",
    "                return expr\n",
    "            #There would be no else here because tensor product simp would have removed that part\n",
    "        else:\n",
    "            return expr        \n",
    "    \n",
    "def autoDropDim(expr):\n",
    "    #print(\"Expression\")\n",
    "    #if isinstance(expr,sp.Mul):\n",
    "        #print(\"type:multiplier\")\n",
    "    #display(expr)\n",
    "    \n",
    "    \n",
    "    if isinstance(expr,sq.TensorProduct):\n",
    "        new_args=[]\n",
    "        for _ in expr.args:\n",
    "            #display(_)\n",
    "            #print(type(_))\n",
    "            if _ != sp.Integer(1):\n",
    "            #if not isinstance(_,core.numbers.One):\n",
    "                new_args.append(_)\n",
    "        #print(\"TensorProduct with %d non-ones in the tensor product\"%len(new_args))\n",
    "        if(len(new_args)==0):\n",
    "            return sp.Integer(1)\n",
    "        else:\n",
    "            return sq.TensorProduct(*new_args)\n",
    "    else:\n",
    "        if expr.has(sq.TensorProduct):\n",
    "            #if it is a sum or a product, run this function for each part and then combine the parts; return the result\n",
    "            if isinstance(expr,sp.Mul) or isinstance(expr,sp.Add):\n",
    "                new_args=[] #list(expr.args)\n",
    "                for _ in expr.args:\n",
    "                    new_args.append(autoDropDim(_))\n",
    "                if isinstance(expr,sp.Mul):        \n",
    "                    return sp.Mul(*new_args)\n",
    "                elif isinstance(expr,sp.Add):\n",
    "                    return sp.Add(*new_args)  \n",
    "                \n",
    "            #There would be no else here because tensor product simp would have removed that part\n",
    "        else:\n",
    "            return expr #when the expression is just an integer or some such\n",
    "\n",
    "\n",
    "        \n",
    "def tsimp(e,pruneMe=True):\n",
    "    res=sq.qapply(powerDrop(sq.tensorproduct.tensor_product_simp(sq.qapply(e)).doit()))\n",
    "    if pruneMe:\n",
    "        return prune(res)\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "def tdsimp(e,pruneMe=True):\n",
    "    res=autoDropDim(sq.qapply(powerDrop(autoDropDim(sq.tensorproduct.tensor_product_simp(sq.qapply(e)).doit()))))\n",
    "    if pruneMe:\n",
    "        return prune(res)\n",
    "    else:\n",
    "        return res\n",
    "    #return autoDropDim(sq.tensorproduct.tensor_product_simp_Mul(e).doit())\n",
    "    #return autoDropDim(sq.tensorproduct.tensor_product_simp_Mul(sq.qapply(e)).doit())\n",
    "    #return autoDropDim(sq.tensorproduct.tensor_product_simp(e).doit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prune(expr,thr=10,remNum=False):\n",
    "    if isinstance(expr,sp.Number): \n",
    "        if remNum==False:\n",
    "            if sp.Abs(expr)<10**(-thr):\n",
    "                return sp.Integer(0)\n",
    "            else:\n",
    "                return expr\n",
    "        else:\n",
    "            return sp.Integer(1)\n",
    "    else:\n",
    "        if expr.has(sp.Number):\n",
    "            #if it is a sum or a product, run this function for each part and then combine the parts; return the result\n",
    "            if isinstance(expr,sp.Mul) or isinstance(expr,sp.Add) or isinstance(expr,sq.TensorProduct):\n",
    "                new_args=[] #list(expr.args)\n",
    "                for _ in expr.args:\n",
    "                    new_args.append(prune(_,thr,remNum))\n",
    "                if isinstance(expr,sp.Mul):        \n",
    "                    return sp.Mul(*new_args)\n",
    "                elif isinstance(expr,sp.Add):\n",
    "                    return sp.Add(*new_args)  \n",
    "                elif isinstance(expr,sq.TensorProduct):\n",
    "                    return sq.TensorProduct(*new_args)  \n",
    "\n",
    "            else:\n",
    "                return expr\n",
    "            #There would be no else here because tensor product simp would have removed that part\n",
    "        else:\n",
    "            return expr        \n",
    "\n",
    "# test=(A[0]*2)\n",
    "# test.has(sp.Number)\n",
    "# prune(test,remNum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "k0=Qubit(0)\n",
    "k1=Qubit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=TensorProduct(k0,k1)\n",
    "w=TensorProduct(k1,k1)\n",
    "#sp.Integer(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle {{\\left|1\\right\\rangle }}\\otimes {{\\left|1\\right\\rangle }}$"
      ],
      "text/plain": [
       "|1>x|1>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 1$"
      ],
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdsimp(Dagger(v)*v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 0$"
      ],
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdsimp(Dagger(w)*v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from sympy.physics.quantum.qubit import Qubit\n",
    "from sympy.physics.quantum.dagger import Dagger\n",
    "from sympy.physics.quantum import TensorProduct as TP\n",
    "import sympy.physics.quantum as sq\n",
    "import sympy as sp\n",
    "\n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending the tensor product functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def prune(expr,thr=10,remNum=False):\n",
    "    if isinstance(expr,sp.Number): \n",
    "        if remNum==False:\n",
    "            if sp.Abs(expr)<10**(-thr):\n",
    "                return sp.Integer(0)\n",
    "            else:\n",
    "                return expr\n",
    "        else:\n",
    "            return sp.Integer(1)\n",
    "    else:\n",
    "        if expr.has(sp.Number):\n",
    "            #if it is a sum or a product, run this function for each part and then combine the parts; return the result\n",
    "            if isinstance(expr,sp.Mul) or isinstance(expr,sp.Add) or isinstance(expr,sq.TensorProduct):\n",
    "                new_args=[] #list(expr.args)\n",
    "                for _ in expr.args:\n",
    "                    new_args.append(prune(_,thr,remNum))\n",
    "                if isinstance(expr,sp.Mul):        \n",
    "                    return sp.Mul(*new_args)\n",
    "                elif isinstance(expr,sp.Add):\n",
    "                    return sp.Add(*new_args)  \n",
    "                elif isinstance(expr,sq.TensorProduct):\n",
    "                    return sq.TensorProduct(*new_args)  \n",
    "\n",
    "            else:\n",
    "                return expr\n",
    "            #There would be no else here because tensor product simp would have removed that part\n",
    "        else:\n",
    "            return expr        \n",
    "\n",
    "# test=(A[0]*2)\n",
    "# test.has(sp.Number)\n",
    "# prune(test,remNum=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Extending Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def powerDrop(expr):\n",
    "    if isinstance(expr,sp.Pow): #TODO: make sure the base is not too complex\n",
    "        # print(\"PowerEncountered\")\n",
    "        if expr.exp>=2:\n",
    "            # print(\"glaba\")\n",
    "            # display(expr.base)\n",
    "            _=sq.qapply(sp.Mul(expr.base,expr.base))\n",
    "            if expr.exp>2:\n",
    "                return powerDrop(_*sp.Pow(expr.base,expr.exp-2))\n",
    "            else:\n",
    "                return _\n",
    "        else:\n",
    "            return expr #autoDropDim(sp.Mul(expr.base,expr.base))\n",
    "    else:\n",
    "        if expr.has(sp.Pow):\n",
    "            #if it is a sum or a product, run this function for each part and then combine the parts; return the result\n",
    "            if isinstance(expr,sp.Mul) or isinstance(expr,sp.Add) or isinstance(expr,sq.TensorProduct):\n",
    "                new_args=[] #list(expr.args)\n",
    "                for _ in expr.args:\n",
    "                    new_args.append(powerDrop(_))\n",
    "                if isinstance(expr,sp.Mul):        \n",
    "                    return sp.Mul(*new_args)\n",
    "                elif isinstance(expr,sp.Add):\n",
    "                    return sp.Add(*new_args)  \n",
    "                elif isinstance(expr,sq.TensorProduct):\n",
    "                    return sq.TensorProduct(*new_args)  \n",
    "\n",
    "            else:\n",
    "                return expr\n",
    "            #There would be no else here because tensor product simp would have removed that part\n",
    "        else:\n",
    "            return expr        \n",
    "    \n",
    "def autoDropDim(expr):\n",
    "    #print(\"Expression\")\n",
    "    #if isinstance(expr,sp.Mul):\n",
    "        #print(\"type:multiplier\")\n",
    "    #display(expr)\n",
    "    \n",
    "    \n",
    "    if isinstance(expr,sq.TensorProduct):\n",
    "        new_args=[]\n",
    "        for _ in expr.args:\n",
    "            #display(_)\n",
    "            #print(type(_))\n",
    "            if _ != sp.Integer(1):\n",
    "            #if not isinstance(_,core.numbers.One):\n",
    "                new_args.append(_)\n",
    "        #print(\"TensorProduct with %d non-ones in the tensor product\"%len(new_args))\n",
    "        if(len(new_args)==0):\n",
    "            return sp.Integer(1)\n",
    "        else:\n",
    "            return sq.TensorProduct(*new_args)\n",
    "    else:\n",
    "        if expr.has(sq.TensorProduct):\n",
    "            #if it is a sum or a product, run this function for each part and then combine the parts; return the result\n",
    "            if isinstance(expr,sp.Mul) or isinstance(expr,sp.Add):\n",
    "                new_args=[] #list(expr.args)\n",
    "                for _ in expr.args:\n",
    "                    new_args.append(autoDropDim(_))\n",
    "                if isinstance(expr,sp.Mul):        \n",
    "                    return sp.Mul(*new_args)\n",
    "                elif isinstance(expr,sp.Add):\n",
    "                    return sp.Add(*new_args)  \n",
    "                \n",
    "            #There would be no else here because tensor product simp would have removed that part\n",
    "        else:\n",
    "            return expr #when the expression is just an integer or some such\n",
    "\n",
    "\n",
    "        \n",
    "def tsimp(e,pruneMe=True):\n",
    "    res=sq.qapply(powerDrop(sq.tensorproduct.tensor_product_simp(sq.qapply(e)).doit()))\n",
    "    if pruneMe:\n",
    "        return prune(res)\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "def tdsimp(e,pruneMe=True):\n",
    "    res=autoDropDim(sq.qapply(powerDrop(autoDropDim(sq.tensorproduct.tensor_product_simp(sq.qapply(e)).doit()))))\n",
    "    if pruneMe:\n",
    "        return prune(res)\n",
    "    else:\n",
    "        return res\n",
    "    #return autoDropDim(sq.tensorproduct.tensor_product_simp_Mul(e).doit())\n",
    "    #return autoDropDim(sq.tensorproduct.tensor_product_simp_Mul(sq.qapply(e)).doit())\n",
    "    #return autoDropDim(sq.tensorproduct.tensor_product_simp(e).doit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing, stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the problem, symbolically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k0=Qubit(0)\n",
    "k1=Qubit(1)\n",
    "\n",
    "ρ=k0*Dagger(k0)\n",
    "\n",
    "ρ_mat=sq.represent(ρ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=TP(k0,k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ρ_=sq.represent(v*Dagger(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0 & 0 & 0 & 0\\\\0 & 1 & 0 & 0\\\\0 & 0 & 0 & 0\\\\0 & 0 & 0 & 0\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[0, 0, 0, 0],\n",
       "[0, 1, 0, 0],\n",
       "[0, 0, 0, 0],\n",
       "[0, 0, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ρ_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1 & 0\\\\0 & 0\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[1, 0],\n",
       "[0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ρ_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the SDP and solve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SolverError",
     "evalue": "Solver 'CVXOPT' failed. Try another solver, or solve with verbose=True for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSolverError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-de9fa22aea35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProblem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mρ1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCVXOPT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\kish\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[0msolve_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msolve_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\kish\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(self, solver, warm_start, verbose, parallel, gp, qcp, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[0mfull_chain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solving_chain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_intermediate_chain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0minverse_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_intermediate_inverse_data\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msolving_inverse_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolution\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_chain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minverse_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\kish\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36munpack_results\u001b[1;34m(self, solution, chain, inverse_data)\u001b[0m\n\u001b[0;32m    715\u001b[0m             raise error.SolverError(\n\u001b[0;32m    716\u001b[0m                     \u001b[1;34m\"Solver '%s' failed. \"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m                     \u001b[1;34m\"Try another solver, or solve with verbose=True for more \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m                     \"information.\")\n\u001b[0;32m    719\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSolverError\u001b[0m: Solver 'CVXOPT' failed. Try another solver, or solve with verbose=True for more information."
     ]
    }
   ],
   "source": [
    "#size of the problem\n",
    "#n=2 #cp.Integer(2)\n",
    "\n",
    "#density matrix to optimize over\n",
    "ρ1 = cp.Variable((2,2), symmetric=True)\n",
    "\n",
    "#density matrix, so positive\n",
    "constraints = [ρ1 >> 0]\n",
    "constraints = [cp.trace(ρ1) == 1]\n",
    "\n",
    "prob = cp.Problem(cp.Maximize(cp.trace(ρ1)), constraints)\n",
    "\n",
    "prob.solve(solver=cp.CVXOPT,verbose=True)\n",
    "\n",
    "                  \n",
    "#cp.trace(ρ_mat @ ρ1)),                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "True True\n",
      "False False\n",
      "False False\n",
      "False False\n"
     ]
    }
   ],
   "source": [
    "#Uttam Bhai's formula\n",
    "#उत्तम भाई\n",
    "\n",
    "for i in [True,False]:\n",
    "    for j in [True,False]:\n",
    "        for k in [True,False]:\n",
    "            print ((i or (j and k)), ((i or j) and (i or k)))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "286px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
